{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computingthe mean of a bunch of images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute the statistics: 1857.66758299\n",
      "Mean of xxx random images transformed 100 each:\n",
      "[0.3865815472784729, 0.3802105031974341, 0.3583346426748059]\n",
      "[0.19097867454776943, 0.1865790861302124, 0.1877423235624467]\n"
     ]
    }
   ],
   "source": [
    "# computing statistics:\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "unlab_ddset = datasets.ImageFolder('./surrogate_dataset/unlab_dataset_055/train_set/',\n",
    "                                  transform = transforms.Compose([transforms.ToTensor()]))\n",
    "unlab_loader = torch.utils.data.DataLoader(unlab_ddset, \n",
    "                                           batch_size = 20,\n",
    "                                           shuffle = True,\n",
    "                                           ) # iterating over the DataLoader gives the tuple (input, target)\n",
    "\n",
    "def compute_mean(loader):\n",
    "    mean = [0, 0, 0]\n",
    "    std = [0, 0, 0]\n",
    "    for i, (images, targets) in enumerate(unlab_loader):\n",
    "        mean0, mean1, mean2 = (0.0, 0.0, 0.0)\n",
    "        std0, std1, std2 = (0.0, 0.0, 0.0)\n",
    "        for num, t in enumerate(images):\n",
    "            mean0 += t[0].mean()\n",
    "            mean1 += t[1].mean()\n",
    "            mean2 += t[2].mean()\n",
    "            std0 += t[0].std()\n",
    "            std1 += t[1].std()\n",
    "            std2 += t[2].std()\n",
    "        mean[0] += mean0/num\n",
    "        mean[1] += mean1/num \n",
    "        mean[2] += mean2/num\n",
    "        std[0] += std0/num\n",
    "        std[1] += std1/num \n",
    "        std[2] += std2/num\n",
    "    return ([x / i for x in mean], [x / i for x in std])\n",
    "\n",
    "st = time.time()\n",
    "mean, std = compute_mean(unlab_loader)\n",
    "end = time.time()\n",
    "print 'Time to compute the statistics: ' + str(end-st)\n",
    "print \"Mean of xxx random images transformed 100 each:\"\n",
    "print mean\n",
    "print std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute the statistics: 57.9964599609\n",
      "Mean of xxx random images transformed 100 each:\n",
      "[0.5236119665307222, 0.5131307008762759, 0.49161293154787855]\n"
     ]
    }
   ],
   "source": [
    "# computing statistics:\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "\n",
    "unlab_ddset = datasets.ImageFolder('./surrogate_dataset/unlab_dataset007/data/',\n",
    "                                  transform = transforms.Compose([transforms.ToTensor()]))\n",
    "unlab_loader = torch.utils.data.DataLoader(unlab_ddset, \n",
    "                                           batch_size = 20,\n",
    "                                           shuffle = True,\n",
    "                                           ) # iterating over the DataLoader gives the tuple (input, target)\n",
    "\n",
    "def compute_mean(loader):\n",
    "    mean = [0, 0, 0]\n",
    "    for i, (images, targets) in enumerate(unlab_loader):\n",
    "        mean0, mean1, mean2 = (0, 0, 0)\n",
    "        for num, t in enumerate(images):\n",
    "            mean0 += t[0].mean()\n",
    "            mean1 += t[1].mean()\n",
    "            mean2 += t[2].mean()\n",
    "        mean[0] += mean0/num\n",
    "        mean[1] += mean1/num \n",
    "        mean[2] += mean2/num    \n",
    "    return [x / i for x in mean]\n",
    "\n",
    "st = time.time()\n",
    "mean = compute_mean(unlab_loader)\n",
    "end = time.time()\n",
    "print 'Time to compute the statistics: ' + str(end-st)\n",
    "print \"Mean of xxx random images transformed 100 each:\"\n",
    "print mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking how the normalization affects the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.FloatTensor,\n",
       " torch.LongTensor,\n",
       " 1734,\n",
       " 1.0,\n",
       " 0.9098039269447327,\n",
       " 0.9888927192077972)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = '002_6'\n",
    "\n",
    "path = '../saving_model/alexNet' + str(experiment) + '.pth.tar'\n",
    "#print path\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.6128879173491645, 0.6060359745417173, 0.5640660479324938],\n",
    "                                 std=[1, 1, 1])\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "unlab_ddset = datasets.ImageFolder('./surrogate_dataset/unlab_train/',\n",
    "                                  transform = transforms.Compose([transforms.ToTensor()]))\n",
    "unlab_loader = torch.utils.data.DataLoader(unlab_ddset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           )\n",
    "\n",
    "for i, data in enumerate(unlab_loader):\n",
    "    break\n",
    "    \n",
    "# data loaded with the pytorch loader and no normalization\n",
    "type(data[0]), type(data[1]), data[1][5], data[0][5].max(), data[0][5].min(), data[0][5].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.FloatTensor,\n",
       " torch.LongTensor,\n",
       " 1052,\n",
       " 0.0829927921295166,\n",
       " -0.5640660524368286,\n",
       " -0.025228471855236287)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment = '002_6'\n",
    "\n",
    "path = '../saving_model/alexNet' + str(experiment) + '.pth.tar'\n",
    "#print path\n",
    "\n",
    "normalize = transforms.Normalize(mean = [0.6128879173491645, 0.6060359745417173, 0.5640660479324938],\n",
    "                                 std=[1, 1, 1])\n",
    "\n",
    "batch_size = 100\n",
    "unlab_ddset = datasets.ImageFolder('./surrogate_dataset/unlab_train/',\n",
    "                                  transform = transforms.Compose([transforms.ToTensor(), normalize]))\n",
    "\n",
    "unlab_loader = torch.utils.data.DataLoader(unlab_ddset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True,\n",
    "                                           )\n",
    "\n",
    "for i, data in enumerate(unlab_loader):\n",
    "    break\n",
    "    \n",
    "# data loaded with the pytorch loader and normalization like follows:\n",
    "# (mean = [0.6128879173491645, 0.6060359745417173, 0.5640660479324938], std=[1, 1, 1])\n",
    "type(data[0]), type(data[1]), data[1][5], data[0][5].max(), data[0][5].min(), data[0][5].mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
